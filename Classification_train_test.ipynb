{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random data for dogs and cats\n",
    "np.random.seed(0) #For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dogs: higher ear flappiness index, lower whisker length\n",
    "dogs_whisker_length = np.random.normal(loc=5, scale=1, size=10)\n",
    "dogs_ear_flappiness_index = np.random.normal(loc=8, scale=1, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cats: lower ear flappiness index, lower whisker length\n",
    "cats_whisker_length = np.random.normal(loc=8, scale=1, size=10)\n",
    "cats_ear_flappiness_index = np.random.normal(loc=5, scale=1, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data\n",
    "dogs_data = np.vstack((dogs_whisker_length, dogs_ear_flappiness_index)).T\n",
    "cats_data = np.vstack((cats_whisker_length, cats_ear_flappiness_index)).T\n",
    "data = np.vstack((dogs_data, cats_data))\n",
    "labels = np.hstack((np.zeros(len(dogs_data)), np.ones(len(cats_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data points\n",
    "plt.scatter(X_train[y_train == 0][:, 0], X_train[y_train == 0][:, 1], labels=\"Training Dogs\")\n",
    "plt.scatter(X_train[y_train == 1][:, 0], X_train[y_train == 1][:, 1], labels=\"Training Cats\")\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='bwr', labels=\"Testing Data\")\n",
    "plt.xlabel('Whisker Length')\n",
    "plt.ylabel('Ear Flappiness Index')\n",
    "plt.title('Dog vs Cat Classification - Training and Testing data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing random linear classifier algorithm\n",
    "def random_linear_classifier(data_dogs, data_cats, k, d):\n",
    "    # d = number of features\n",
    "    best_error = float('inf')\n",
    "    best_theta = None\n",
    "    best_theta0 = None\n",
    "    \n",
    "    for _ in range(k):\n",
    "        theta = np.random.normal(size=d)\n",
    "        theta0 = np.random.normal()\n",
    "        \n",
    "        error = compute_error(data_dogs, data_cats, theta, theta0)\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_theta = theta\n",
    "            best_theta0 = theta0\n",
    "            \n",
    "    return best_theta, best_theta0\n",
    "\n",
    "def compute_error(data_dogs, data_cats, theta, theta0): \n",
    "    error = 0\n",
    "    for x_dog in data_dogs:\n",
    "        if np.dot(theta, x_dog) + theta0 <= 0:\n",
    "            error += 1\n",
    "    for x_cat in data_cats:\n",
    "        if np.dot(theta, x_cat) + theta0 > 0:\n",
    "            error += 1\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for k-fold cross-validation\n",
    "def cross_validate(data_dogs, data_cats, k, d):\n",
    "    best_error = float('inf')\n",
    "    best_theta = None\n",
    "    best_theta0 = None\n",
    "    \n",
    "    \n",
    "    for _ in range(k):\n",
    "        theta = np.random.normal(size=d)\n",
    "        theta0 = np.random.normal()\n",
    "        \n",
    "        error = compute_error(data_dogs, data_cats, theta, theta0)\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_theta = theta\n",
    "            best_theta0 = theta0\n",
    "            \n",
    "    return best_theta, best_theta0, best_error\n",
    "\n",
    "def compute_error(data_dogs, data_cats, theta, theta0):\n",
    "    error = 0\n",
    "    for x_dog in data_dogs:\n",
    "        if np.dot(theta, x_dog) + theta0 <= 0:\n",
    "            error += 1\n",
    "            \n",
    "    for x_cat in data_cats:\n",
    "        if np.dot(theta, x_cat) + theta0 > 0:\n",
    "            error +=1\n",
    "    return error\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for k-fold cross-validation\n",
    "def cross_validate(data_dogs, data_cats, k_values, d, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    avg_errors = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        errors = []\n",
    "        \n",
    "        for train_index, val_index in kf.split(data_dogs):\n",
    "            X_train_fold = np.vstack((data_dogs[train_index], data_cats[train_index]))\n",
    "            y_train_fold = np.hstack((np.zeros(len(train_index)), np.ones(len(train_index))))\n",
    "            X_val_fold = np.vstack((data_dogs[val_index], data_cats[val_index]))\n",
    "            y_val_fold = np.hstack((np.zeros(len(val_index)), np.ones(len(val_index))))\n",
    "            \n",
    "            best_theta_fold, best_theta0_fold, error = random_linear_classifier(X_train_fold[y_train_fold == 0],\n",
    "                                                                                X_train_fold[y_train_fold == 1],\n",
    "                                                                                k, d)\n",
    "            \n",
    "            errors.append(compute_error(X_val_fold[y_val_fold == 0], X_val_fold[y_val_fold == 1],\n",
    "                                        best_theta_fold, best_theta0_fold))\n",
    "            \n",
    "    avg_errors.append(np.mean(errors))\n",
    "    \n",
    "#Define k values to try\n",
    "k_values = [1, 10, 50, 100, 200, 350]\n",
    "\n",
    "best_k = cross_validate(dogs_data, cats_data, k_values, d=2)\n",
    "\n",
    "print(f\"Best value of k: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run random linear classifier algorithm on training data \n",
    "#k = 100 #Number of iterations\n",
    "k=best_k\n",
    "d = 2 #Number of features\n",
    "best_theta_train, best_theta0_train, train_error = random_linear_classifier(\n",
    "    X_train[y_train == 0], X_train[y_train == 1], k, d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the decision boundry on training data\n",
    "\n",
    "x_vals_train = np.linspace(2, 10, 100)\n",
    "y_vals_train = (-best_theta_train[0] / best_theta_train[1]) * x_vals_train - (best_theta0_train / best_theta_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train == 0][:, 0], X_train[y_train == 0][:, 1], label = 'Training Dogs')\n",
    "plt.scatter(X_train[y_train == 1][:, 0], X_train[y_train == 1][:, 1], label = 'Training Cats')\n",
    "plt.plot(x_vals_train, y_vals_train, color='red', linestyle='--', label='Training Decision Boundary')\n",
    "\n",
    "#Set same limits for x and y axes\n",
    "plt.xlim([3.5, 11])\n",
    "plt.ylim([2, 10])\n",
    "plt.xlabel('Whisker Length')\n",
    "plt.ylabel('Ear Flappiness Index')\n",
    "plt.title('Dog vs Cat Classification - Training Data with Best Fit Line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Error: {train_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute testing error\n",
    "test_error = compute_error(X_test[y_test == 0], X_test[y_test == 1], best_theta_train, best_theta0_train)\n",
    "print(f\"Testing error: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the actual test data and predicted test data\n",
    "plt.scatter(X_test[y_test == 0][:, 0], X_test[y_test == 0][:, 1], label='Actual Dogs')\n",
    "plt.scatter(X_test[y_test == 1][:, 0], X_test[y_test == 1][:, 1], label='Actual Cats')\n",
    "\n",
    "#Predict test data points using the decision boundry\n",
    "predicted_labels = np.zeros_like(y_test)\n",
    "for i, x_test in enumerate(X_test):\n",
    "    if np.dot(best_theta_train, x_test) + best_theta0_train > 0:\n",
    "        predicted_labels[i] = 1\n",
    "        \n",
    "#Plot predicted test data points\n",
    "plt.scatter(X_test[predicted_labels == 0][:, 0], X_test[predicted_labels == 0][:, 1], marker='x', label='Predicted Dogs', color='green')\n",
    "plt.scatter(X_test[predicted_labels == 1][:, 0], X_test[predicted_labels == 1][:, 1], marker='x', label='Predicted Cats', color='orange')\n",
    "\n",
    "#Plot decision boundary\n",
    "plt.plot(x_vals_test, y_vals_test, color='red', linestyle='--', label='Decision Boundary')\n",
    "\n",
    "plt.xlabel('Whisker Length')\n",
    "plt.ylabel('Ear Flappiness Index')\n",
    "plt.title('Dog vs Cat Classification - Actual vs Predicted Test Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
